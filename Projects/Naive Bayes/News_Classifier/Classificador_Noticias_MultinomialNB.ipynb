{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificador_Noticias_MultinomialNB",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classificador de notícias usando o algoritmo Multinomial Naive Bayes\n",
        "\n",
        "* Neste projeto foi construído um classificador de notícias para determinar sua categoria utilizando o algoritmo Multinomial Naive Bayes.\n",
        "\n",
        "\n",
        "* Sua documentação pode ser encontrada no seguinte link: \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "\n",
        "* O classificador Multinomial Naive Bayes é recomendado quando se trabalha com variáveis discretas. \n",
        "\n",
        "\n",
        "* A base de dados utilizada pode ser encontrada a seguir: \n",
        "http://qwone.com/~jason/20Newsgroups/"
      ],
      "metadata": {
        "id": "PZWUBMK8mjZA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QoPGWk8nmTlC"
      },
      "outputs": [],
      "source": [
        "# Importação dos pacotes utilizados\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo as categorias das notícias para limitar os tipos que quero utilizar\n",
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "metadata": {
        "id": "qcEUSOm2mg4d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a base de dados de treino \n",
        "twenty_train = fetch_20newsgroups(subset='train', categories = categories, shuffle=True, random_state = 42)"
      ],
      "metadata": {
        "id": "D1lLy9DRmhAS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes da base que foram definidas\n",
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHAijDoHmhBe",
        "outputId": "5ba294a8-7129-4e47-96aa-ea499ade9569"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho da base de dados\n",
        "len(twenty_train.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLMYIAMEmhCd",
        "outputId": "2de1378a-d250-4cfb-e810-c4482d78dec9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando alguns dados\n",
        "print('\\n'.join(twenty_train.data[0].split('\\n')[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SxQP3jmhD6",
        "outputId": "90a3b79e-1e5c-404c-8bb8-2853818c41e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: sd345@city.ac.uk (Michael Collier)\n",
            "Subject: Converting images to HP LaserJet III?\n",
            "Nntp-Posting-Host: hampton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as respostas dos dados acima\n",
        "print(twenty_train.target_names[twenty_train.target[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxO838ndmhFG",
        "outputId": "3358f50b-efdd-4160-ce13-614f964c790c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# O Scikit-Learn registrou as respostas como qualitativa a fim de aumentar a velocidade\n",
        "twenty_train.target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnmZOg3TmhGo",
        "outputId": "05b454c7-54d0-4cc4-cf87-a1a39404488c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Construindo o Bag of Words (Saco de Palavras)"
      ],
      "metadata": {
        "id": "vycuPSmZuTNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizando as palavras, ou seja, reduzindo as palavras\n",
        "count_vector = CountVectorizer()\n",
        "X_train_counts = count_vector.fit_transform(twenty_train.data)\n",
        "count_vector.vocabulary_.get(u'algorithm')\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXr9BunmhHq",
        "outputId": "2c17bd2b-d9f2-4bfd-c686-e0cdddbc4136"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# De ocorrências para frequências resultando em uma matriz esparsa - Tf-idf\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-c2HbVomhJQ",
        "outputId": "053c288d-7cf5-4694-8339-4d62f6ac9e55"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o modelo Multinomial Naive Bayes\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "QCEfHEYBmhK4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando as previsões com base em frases criadas\n",
        "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
        "X_new_counts = count_vector.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j98prCQQmhMQ",
        "outputId": "85fe062b-2721-4970-ed1b-de5951effd3b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => soc.religion.christian\n",
            "'OpenGL on the GPU is fast' => comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo previu as frases da maneira correta"
      ],
      "metadata": {
        "id": "1HApN96Qx9JG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### É possível fazer este processo através do uso de Pipeline\n",
        "\n",
        "* Nas linhas a seguir será utilizado Pipeline com o mesmo objetivo"
      ],
      "metadata": {
        "id": "Zh9Mb9UUyUFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do Pipeline com as transformações necessárias nos dados e o modelo Multinomial\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB()),\n",
        "])"
      ],
      "metadata": {
        "id": "tVobjDDPmhN6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit do modelo\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "id": "LIxdtCzWmhPI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a Acurácia do modelo\n",
        "twenty_test = fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = 42)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "print('Acurácia obtida: {}'.format(np.mean(predicted == twenty_test.target)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwtJ3yC2mhQe",
        "outputId": "3bacad65-e459-4e77-9371-bf795117ceae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia obtida: 0.8348868175765646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas obtidas\n",
        "print(metrics.classification_report(twenty_test.target, predicted, target_names = twenty_test.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqnBVDsK18Fd",
        "outputId": "0d68f16d-792e-427a-c6b1-5c935ea90aa4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.97      0.60      0.74       319\n",
            "         comp.graphics       0.96      0.89      0.92       389\n",
            "               sci.med       0.97      0.81      0.88       396\n",
            "soc.religion.christian       0.65      0.99      0.78       398\n",
            "\n",
            "              accuracy                           0.83      1502\n",
            "             macro avg       0.89      0.82      0.83      1502\n",
            "          weighted avg       0.88      0.83      0.84      1502\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru3m9rF1mhSC",
        "outputId": "f5edf77e-75fa-44c1-be49-0984c246d5d4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[192,   2,   6, 119],\n",
              "       [  2, 347,   4,  36],\n",
              "       [  2,  11, 322,  61],\n",
              "       [  2,   2,   1, 393]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}